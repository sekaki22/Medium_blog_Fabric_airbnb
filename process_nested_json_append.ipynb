{"cells":[{"attachments":{},"cell_type":"markdown","id":"d055c8b4","metadata":{},"source":["## Process nested json\n","\n","The 'pipeline_child_get_cities' triggers this Notebook within Fabric and reads and processes the nested json so that it can be . The Data Factory pipeline provides the following **city** parameter so that it is known which file to open.\n","Pyspark functionality  is used to process the files as efficient as possible"]},{"cell_type":"code","execution_count":null,"id":"5dbbbc87-3c84-4dac-8c8d-7cba10f018db","metadata":{},"outputs":[{"data":{"application/vnd.livy.statement-meta+json":{"execution_finish_time":"2023-08-02T21:10:41.6064997Z","execution_start_time":"2023-08-02T21:10:38.0618602Z","livy_statement_state":"available","parent_msg_id":"dde7c4a5-7eb4-4b9d-b254-60d0ca9ab97b","queued_time":"2023-08-02T21:10:37.6703094Z","session_id":"68ba2825-2254-4726-afde-f9f488db6901","session_start_time":null,"spark_jobs":{"jobs":[{"completionTime":"2023-08-02T21:10:40.915GMT","dataRead":54910684,"dataWritten":0,"description":"Job group for statement 16:\n# First load in json and flatten the data structure, alle we need for now are the fields\n\nfrom pyspark.sql.functions import explode, col\n\ndf = spark.read.format('json')          .option(\"inferSchema\", \"true\")          .option(\"multiLine\", \"true\")          .load(f'Files/store/opendatasoft/{filename}.json')          .select(explode(\"records\").alias(\"data\"))          .select(\"data.*\")          .select(\"fields.*\")","displayName":"load at NativeMethodAccessorImpl.java:0","jobGroup":"16","jobId":20,"killedTasksSummary":{},"name":"load at NativeMethodAccessorImpl.java:0","numActiveStages":0,"numActiveTasks":0,"numCompletedIndices":1,"numCompletedStages":1,"numCompletedTasks":1,"numFailedStages":0,"numFailedTasks":0,"numKilledTasks":0,"numSkippedStages":0,"numSkippedTasks":0,"numTasks":1,"rowCount":1,"stageIds":[28],"status":"SUCCEEDED","submissionTime":"2023-08-02T21:10:39.862GMT","usageDescription":""}],"limit":20,"numbers":{"FAILED":0,"RUNNING":0,"SUCCEEDED":1,"UNKNOWN":0},"rule":"ALL_DESC"},"spark_pool":null,"state":"finished","statement_id":16},"text/plain":["StatementMeta(, 68ba2825-2254-4726-afde-f9f488db6901, 16, Finished, Available)"]},"metadata":{},"output_type":"display_data"}],"source":["# First load in json and flatten the data structure, all we need for now are the fields\n","# city parameter is provided by pipeline\n","\n","from pyspark.sql.functions import explode, col\n","\n","df = spark.read.format('json')\\\n","          .option(\"inferSchema\", \"true\")\\\n","          .option(\"multiLine\", \"true\")\\\n","          .load(f'Files/store/opendatasoft/airbnb-listings-{city}.json')\\\n","          .select(explode(\"records\").alias(\"data\"))\\\n","          .select(\"data.*\")\\\n","          .select(\"fields.*\")"]},{"attachments":{},"cell_type":"markdown","id":"c4658ce3","metadata":{},"source":["Spark reads data in as Spark Dataframe. From this it is recommended to write the dataframe to parquet or delta format. In this case, the dataframe is written to delta format. "]},{"cell_type":"code","execution_count":9,"id":"ba693899-caa7-402c-97bb-c8c8a8b9ff78","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[{"data":{"application/vnd.livy.statement-meta+json":{"execution_finish_time":"2023-08-02T20:58:00.8717943Z","execution_start_time":"2023-08-02T20:57:54.6155805Z","livy_statement_state":"available","parent_msg_id":"6c144467-2991-44c2-9610-6a6b2885d2d6","queued_time":"2023-08-02T20:57:54.2183365Z","session_id":"68ba2825-2254-4726-afde-f9f488db6901","session_start_time":null,"spark_jobs":{"jobs":[{"completionTime":"2023-08-02T20:57:59.836GMT","dataRead":5547,"dataWritten":0,"description":"Delta: Job group for statement 11:\ndf.write.format(\"delta\")    .mode(\"overwrite\")    .save(\"Files/loaded/opendatasoft/airbnb-listings/\"): Compute snapshot for version: 0","displayName":"toString at String.java:2994","jobGroup":"11","jobId":19,"killedTasksSummary":{},"name":"toString at String.java:2994","numActiveStages":0,"numActiveTasks":0,"numCompletedIndices":1,"numCompletedStages":1,"numCompletedTasks":1,"numFailedStages":0,"numFailedTasks":0,"numKilledTasks":0,"numSkippedStages":2,"numSkippedTasks":51,"numTasks":52,"rowCount":50,"stageIds":[27,25,26],"status":"SUCCEEDED","submissionTime":"2023-08-02T20:57:59.783GMT","usageDescription":""},{"completionTime":"2023-08-02T20:57:59.751GMT","dataRead":4077,"dataWritten":5547,"description":"Delta: Job group for statement 11:\ndf.write.format(\"delta\")    .mode(\"overwrite\")    .save(\"Files/loaded/opendatasoft/airbnb-listings/\"): Compute snapshot for version: 0","displayName":"toString at String.java:2994","jobGroup":"11","jobId":18,"killedTasksSummary":{},"name":"toString at String.java:2994","numActiveStages":0,"numActiveTasks":0,"numCompletedIndices":50,"numCompletedStages":1,"numCompletedTasks":50,"numFailedStages":0,"numFailedTasks":0,"numKilledTasks":0,"numSkippedStages":1,"numSkippedTasks":1,"numTasks":51,"rowCount":54,"stageIds":[24,23],"status":"SUCCEEDED","submissionTime":"2023-08-02T20:57:58.726GMT","usageDescription":""},{"completionTime":"2023-08-02T20:57:58.532GMT","dataRead":11747,"dataWritten":4077,"description":"Delta: Job group for statement 11:\ndf.write.format(\"delta\")    .mode(\"overwrite\")    .save(\"Files/loaded/opendatasoft/airbnb-listings/\"): Compute snapshot for version: 0","displayName":"toString at String.java:2994","jobGroup":"11","jobId":17,"killedTasksSummary":{},"name":"toString at String.java:2994","numActiveStages":0,"numActiveTasks":0,"numCompletedIndices":1,"numCompletedStages":1,"numCompletedTasks":1,"numFailedStages":0,"numFailedTasks":0,"numKilledTasks":0,"numSkippedStages":0,"numSkippedTasks":0,"numTasks":1,"rowCount":8,"stageIds":[22],"status":"SUCCEEDED","submissionTime":"2023-08-02T20:57:58.442GMT","usageDescription":""},{"completionTime":"2023-08-02T20:57:57.887GMT","dataRead":0,"dataWritten":0,"description":"Job group for statement 11:\ndf.write.format(\"delta\")    .mode(\"overwrite\")    .save(\"Files/loaded/opendatasoft/airbnb-listings/\")","displayName":"Job group for statement 11:\ndf.write.format(\"delta\")    .mode(\"overwrite\")    .save(\"Files/loaded/opendatasoft/airbnb-listings/\")","jobGroup":"11","jobId":16,"killedTasksSummary":{},"name":"","numActiveStages":0,"numActiveTasks":0,"numCompletedIndices":0,"numCompletedStages":0,"numCompletedTasks":0,"numFailedStages":0,"numFailedTasks":0,"numKilledTasks":0,"numSkippedStages":0,"numSkippedTasks":0,"numTasks":0,"rowCount":0,"stageIds":[],"status":"SUCCEEDED","submissionTime":"2023-08-02T20:57:57.887GMT","usageDescription":""},{"completionTime":"2023-08-02T20:57:57.752GMT","dataRead":20843571,"dataWritten":18733531,"description":"Job group for statement 11:\ndf.write.format(\"delta\")    .mode(\"overwrite\")    .save(\"Files/loaded/opendatasoft/airbnb-listings/\")","displayName":"save at NativeMethodAccessorImpl.java:0","jobGroup":"11","jobId":15,"killedTasksSummary":{},"name":"save at NativeMethodAccessorImpl.java:0","numActiveStages":0,"numActiveTasks":0,"numCompletedIndices":1,"numCompletedStages":1,"numCompletedTasks":1,"numFailedStages":0,"numFailedTasks":0,"numKilledTasks":0,"numSkippedStages":1,"numSkippedTasks":1,"numTasks":2,"rowCount":20000,"stageIds":[20,21],"status":"SUCCEEDED","submissionTime":"2023-08-02T20:57:56.346GMT","usageDescription":""},{"completionTime":"2023-08-02T20:57:56.271GMT","dataRead":54910684,"dataWritten":20843571,"description":"Job group for statement 11:\ndf.write.format(\"delta\")    .mode(\"overwrite\")    .save(\"Files/loaded/opendatasoft/airbnb-listings/\")","displayName":"save at NativeMethodAccessorImpl.java:0","jobGroup":"11","jobId":14,"killedTasksSummary":{},"name":"save at NativeMethodAccessorImpl.java:0","numActiveStages":0,"numActiveTasks":0,"numCompletedIndices":1,"numCompletedStages":1,"numCompletedTasks":1,"numFailedStages":0,"numFailedTasks":0,"numKilledTasks":0,"numSkippedStages":0,"numSkippedTasks":0,"numTasks":1,"rowCount":10001,"stageIds":[19],"status":"SUCCEEDED","submissionTime":"2023-08-02T20:57:55.072GMT","usageDescription":""}],"limit":20,"numbers":{"FAILED":0,"RUNNING":0,"SUCCEEDED":6,"UNKNOWN":0},"rule":"ALL_DESC"},"spark_pool":null,"state":"finished","statement_id":11},"text/plain":["StatementMeta(, 68ba2825-2254-4726-afde-f9f488db6901, 11, Finished, Available)"]},"metadata":{},"output_type":"display_data"}],"source":["# Save dataframe to delta table\n","\n","df.write.format(\"delta\")\\\n","    .mode(\"append\")\\\n","    .save(f'Files/loaded/opendatasoft/airbnb-listings/')"]}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"display_name":"Synapse PySpark","name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"host":{"synapse_widget":{"state":{},"token":"8e709cb8-a383-492b-829a-4fd1e048c2b9"}},"language":"python","ms_spell_check":{"ms_spell_check_language":"en"}},"notebook_environment":{},"nteract":{"version":"nteract-front-end@1.0.0"},"save_output":true,"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{},"enableDebugMode":false}},"synapse_widget":{"state":{},"version":"0.1"},"trident":{"lakehouse":{"default_lakehouse":"d571d57b-b1a7-4148-b967-745bc4c44240","default_lakehouse_name":"sb_lakehouse","default_lakehouse_workspace_id":"2d2772c8-0868-471e-a900-374b70d8e1ce","known_lakehouses":[{"id":"d571d57b-b1a7-4148-b967-745bc4c44240"}]}},"widgets":{}},"nbformat":4,"nbformat_minor":5}
