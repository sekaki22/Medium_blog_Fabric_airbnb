{"nbformat":4,"nbformat_minor":5,"metadata":{"language_info":{"name":"python"},"kernelspec":{"name":"synapse_pyspark","display_name":"Synapse PySpark"},"microsoft":{"language":"python","ms_spell_check":{"ms_spell_check_language":"en"},"host":{}},"kernel_info":{"name":"synapse_pyspark"},"widgets":{},"nteract":{"version":"nteract-front-end@1.0.0"},"save_output":true,"spark_compute":{"compute_id":"/trident/default","session_options":{"enableDebugMode":false,"conf":{}}},"notebook_environment":{},"synapse_widget":{"version":"0.1","state":{}},"trident":{"lakehouse":{"default_lakehouse":"d571d57b-b1a7-4148-b967-745bc4c44240","known_lakehouses":[{"id":"d571d57b-b1a7-4148-b967-745bc4c44240"}],"default_lakehouse_name":"sb_lakehouse","default_lakehouse_workspace_id":"2d2772c8-0868-471e-a900-374b70d8e1ce"}}},"cells":[{"cell_type":"markdown","source":["# Track Machine Learning experiments and models\n","\n","A machine learning model is a file that has been trained to recognize certain types of patterns. You train a model over a set of data, providing it an algorithm that it can use to reason over and learn from those data. Once you have trained the model, you can use it to reason over data that it hasn't seen before, and make predictions about that data.\n","\n","In this notebook, you will learn the basic steps to run an experiment, add a model version to track run metrics and parameters and register a model.\n"],"metadata":{},"id":"80a9712f-01e7-486e-a290-f061e6d2d488"},{"cell_type":"markdown","source":["## Limitation alert\n","\n","Right of the bat we confront a major limitation of MLLib. MLLib offers a multilayer Perceptron, however the output layer can not be adjusted to be a linear function. Therefore regression is not possible within the MLLib library. For that reason, we will unfortunately not be using the Power of Spark for the training of our Neural Net. Instead of **MLLib** we will be using **Pytorch**"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"01f320be-8b27-4255-a0f8-611346ebd309"},{"cell_type":"markdown","source":[],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"c1b5b090-eac6-4bd2-8612-83f16f9cc3d1"},{"cell_type":"markdown","source":["#### Step 1: Import libraries\n"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"aae2a778-592f-4604-9189-cd9ff063b600"},{"cell_type":"code","source":["import mlflow\n","import mlflow.pytorch\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, TensorDataset\n","import torch.nn.init as init\n","from sklearn.metrics import mean_squared_error, r2_score\n","import mlflow.sklearn\n","from pyspark.ml import Pipeline\n","from pyspark.ml.regression import LinearRegression, DecisionTreeRegressor, RandomForestRegressor\n","from pyspark.ml.feature import VectorAssembler\n","from pyspark.ml.evaluation import RegressionEvaluator\n","\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"f29bf580-53de-48f1-a7c1-2dc479c0524f","statement_id":4,"state":"finished","livy_statement_state":"available","queued_time":"2023-09-08T13:39:33.4446609Z","session_start_time":null,"execution_start_time":"2023-09-08T13:39:33.9181602Z","execution_finish_time":"2023-09-08T13:39:59.188633Z","spark_jobs":{"numbers":{"FAILED":0,"RUNNING":0,"SUCCEEDED":0,"UNKNOWN":0},"jobs":[],"limit":20,"rule":"ALL_DESC"},"parent_msg_id":"79826f11-5f7c-457b-8830-facc3b9786d8"},"text/plain":"StatementMeta(, f29bf580-53de-48f1-a7c1-2dc479c0524f, 4, Finished, Available)"},"metadata":{}}],"execution_count":2,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"31b22360-ef95-468c-b622-090b6b4e21f0"},{"cell_type":"markdown","source":["#### Step 2: Setup ML FLow experiment"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"ac5101f0-87e2-4e75-aa1b-d068a6d4d56f"},{"cell_type":"code","source":["\n","torch.set_default_dtype(torch.float32)\n","#mlflow.set_experiment(\"price_predictions_airbnb_neural_net\")\n","mlflow.set_experiment(\"airbnb_blog_large_experiment\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"f29bf580-53de-48f1-a7c1-2dc479c0524f","statement_id":5,"state":"finished","livy_statement_state":"available","queued_time":"2023-09-08T13:40:38.5552288Z","session_start_time":null,"execution_start_time":"2023-09-08T13:40:39.0591608Z","execution_finish_time":"2023-09-08T13:40:42.6527812Z","spark_jobs":{"numbers":{"FAILED":0,"RUNNING":0,"SUCCEEDED":0,"UNKNOWN":0},"jobs":[],"limit":20,"rule":"ALL_DESC"},"parent_msg_id":"290594c7-3eee-4215-8cb1-2bcc3d79327d"},"text/plain":"StatementMeta(, f29bf580-53de-48f1-a7c1-2dc479c0524f, 5, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stderr","text":["2023/09/08 13:40:39 INFO mlflow.tracking.fluent: Experiment with name 'airbnb_blog_large_experiment' does not exist. Creating a new experiment.\n"]},{"output_type":"execute_result","execution_count":14,"data":{"text/plain":"<Experiment: artifact_location='', creation_time=1694180440967, experiment_id='665f1ca1-8479-49e8-b3d1-f4da6375457b', last_update_time=None, lifecycle_stage='active', name='airbnb_blog_large_experiment', tags={}>"},"metadata":{}}],"execution_count":3,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"1f75c2b3-0ade-43cb-bbb2-5e470f7a3546"},{"cell_type":"markdown","source":["#### Step 3: Import and prepare data for MLLib models\n","\n"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"c1326669-0e75-4a4d-b3af-4e05a2e608b9"},{"cell_type":"code","source":["# Import the dataset\n","\n","airbnb = spark.read.parquet(\"Files/transformed/opendatasoft/airbnb-listings\").dropna()\n","\n","# Split train & test\n","train_df, test_df = airbnb.randomSplit([0.7, 0.3])\n","\n","#Define x features\n","x_features = [column for column in airbnb.columns if column != 'price']\n","\n","# Store in vector\n","vector_assembler = VectorAssembler(inputCols=x_features, \n","                                outputCol=\"features\",\n","                                handleInvalid=\"skip\")\n","train_df = vector_assembler.transform(train_df)\n","test_df = vector_assembler.transform(test_df)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"f29bf580-53de-48f1-a7c1-2dc479c0524f","statement_id":8,"state":"finished","livy_statement_state":"available","queued_time":"2023-09-08T13:44:34.4892165Z","session_start_time":null,"execution_start_time":"2023-09-08T13:44:34.8897708Z","execution_finish_time":"2023-09-08T13:44:37.408846Z","spark_jobs":{"numbers":{"FAILED":0,"RUNNING":0,"SUCCEEDED":1,"UNKNOWN":0},"jobs":[{"displayName":"parquet at NativeMethodAccessorImpl.java:0","dataWritten":0,"dataRead":0,"rowCount":0,"usageDescription":"","jobId":8,"name":"parquet at NativeMethodAccessorImpl.java:0","description":"Job group for statement 8:\n# Import the dataset\n\nairbnb = spark.read.parquet(\"Files/transformed/opendatasoft/airbnb-listings\").dropna()\n\n# Split train & test\ntrain_df, test_df = airbnb.randomSplit([0.7, 0.3])\n\n#Define x features\nx_features = [column for column in airbnb.columns if column != 'price']\n\n# Store in vector\nvector_assembler = VectorAssembler(inputCols=x_features, \n                                outputCol=\"features\",\n                                handleInvalid=\"skip\")\ntrain_df = vector_assembler.transform(train_df)\ntest_df = vector_assembler.transform(test_df)","submissionTime":"2023-09-08T13:44:35.701GMT","completionTime":"2023-09-08T13:44:36.207GMT","stageIds":[12],"jobGroup":"8","status":"SUCCEEDED","numTasks":1,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}}],"limit":20,"rule":"ALL_DESC"},"parent_msg_id":"87fe1d23-151b-496d-b96d-bf4b72ef51e9"},"text/plain":"StatementMeta(, f29bf580-53de-48f1-a7c1-2dc479c0524f, 8, Finished, Available)"},"metadata":{}}],"execution_count":6,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"dc7d91bd-3468-40df-b3e8-a715d2fb55a9"},{"cell_type":"markdown","source":["#### Step 4: Generate function to run following ML algorithms\n","\n","#### Linear Regression\n","#### Decision Tree\n","#### Random Forrest"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"5d594b94-7358-4608-8104-e2575a74b5aa"},{"cell_type":"code","source":["# Generate function in which Ml Flow experiment is kicked off\n","from mlflow.models.signature import infer_signature\n","import numpy as np\n","\n","def train_evaluate(model, name, train_df, test_df):\n","    with mlflow.start_run(run_name=name) as run:\n","        # Train the model\n","        mlflow.log_param(\"num_training_rows\", train_df.count())\n","        model = model.setFeaturesCol(\"features\").setLabelCol(\"price\")\n","        trained_model = model.fit(train_df)\n","        \n","        # Make predictions\n","        predictions = trained_model.transform(test_df)\n","\n","        input_sample = train_df.drop(\"price\")\n","        output_sample = predictions.select(\"prediction\")\n","        #signature = infer_signature(input_sample, output_sample)\n","        \n","        # Evaluate the model for mse\n","        evaluator_mse = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\", metricName=\"mse\")\n","        mse = evaluator_mse.evaluate(predictions)\n","\n","        # Evaluate the model for mae\n","        evaluator_mae = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\", metricName=\"mae\")\n","        mae = evaluator_mae.evaluate(predictions)        \n","\n","        # Evaluate r2 if model is linear regression\n","        if name == \"Linear Regression\":\n","            evaluator_r2 = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\", metricName=\"r2\")\n","            r2 = evaluator_r2.evaluate(predictions)   \n"," \n","        #Store artifacts\n","        pred_array = np.array(predictions.select(\"prediction\").limit(100).collect()).flatten()\n","        truth_array = np.array(predictions.select(\"price\").limit(100).collect()).flatten()\n","        \n","        # Combine predictions and ground truth into a single array\n","        combined_array = np.stack((pred_array, truth_array), axis=-1)\n","        print(combined_array)\n","\n","        # Save them to a .npy file\n","        np.save(\"combined_predictions_truth.npy\", combined_array)\n","        \n","        # Log the combined numpy array as an artifact\n","        mlflow.log_artifact(\"combined_predictions_truth.npy\")\n","        # Log metrics\n","        mlflow.log_metric(\"mse\", mse)\n","        mlflow.log_metric(\"mae\", mae)\n","        if name == \"Linear Regression\":\n","            mlflow.log_metric(\"r2\", r2)\n","\n","        mlflow.spark.log_model(trained_model, \"price_predictions_airbnb\")\n","        print(\"Model saved in run_id=%s\" % run.info.run_id)\n","\n","        #mlflow.register_model(\n","        #\"runs:/{}/price_predictions_airbnb\".format(run.info.run_id), name)\n","        \n","        print(f\"{name} MSE: {mse}\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"f29bf580-53de-48f1-a7c1-2dc479c0524f","statement_id":9,"state":"finished","livy_statement_state":"available","queued_time":"2023-09-08T13:44:40.4156505Z","session_start_time":null,"execution_start_time":"2023-09-08T13:44:40.8153484Z","execution_finish_time":"2023-09-08T13:44:41.1104905Z","spark_jobs":{"numbers":{"FAILED":0,"RUNNING":0,"SUCCEEDED":0,"UNKNOWN":0},"jobs":[],"limit":20,"rule":"ALL_DESC"},"parent_msg_id":"131de5b6-09f2-4f30-b4dd-1e4b946cf8d4"},"text/plain":"StatementMeta(, f29bf580-53de-48f1-a7c1-2dc479c0524f, 9, Finished, Available)"},"metadata":{}}],"execution_count":7,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"52cf38aa-a9f3-47ec-be0c-cbe1810d48b7"},{"cell_type":"markdown","source":[],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"c33948db-794f-4113-b82f-d2a83609e3e1"},{"cell_type":"markdown","source":["#### Step 5: Run experiment"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"d89ee2c9-4cce-4bfe-8a75-40e284eb9aaa"},{"cell_type":"code","source":["# Test multiple regression models\n","\n","models = {\n","    \"Linear Regression\": LinearRegression(),\n","    \"Decision Tree\": DecisionTreeRegressor(),\n","    \"Random Forest\": RandomForestRegressor(numTrees = 1000)\n","}\n","\n","for name, model in models.items():\n","    train_evaluate(model, name, train_df, test_df)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"f29bf580-53de-48f1-a7c1-2dc479c0524f","statement_id":10,"state":"finished","livy_statement_state":"available","queued_time":"2023-09-08T13:44:43.9984788Z","session_start_time":null,"execution_start_time":"2023-09-08T13:44:44.544594Z","execution_finish_time":"2023-09-08T13:50:50.5552019Z","spark_jobs":{"numbers":{"FAILED":0,"RUNNING":0,"SUCCEEDED":59,"UNKNOWN":0},"jobs":[{"displayName":"parquet at treeModels.scala:491","dataWritten":3247453,"dataRead":3994184,"rowCount":125784,"usageDescription":"","jobId":67,"name":"parquet at treeModels.scala:491","description":"Job group for statement 10:\n# Test multiple regression models\n\nmodels = {\n    \"Linear Regression\": LinearRegression(),\n    \"Decision Tree\": DecisionTreeRegressor(),\n    \"Random Forest\": RandomForestRegressor(numTrees = 1000)\n}\n\nfor name, model in models.items():\n    train_evaluate(model, name, train_df, test_df)","submissionTime":"2023-09-08T13:50:41.945GMT","completionTime":"2023-09-08T13:50:42.601GMT","stageIds":[89,90],"jobGroup":"10","status":"SUCCEEDED","numTasks":9,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":8,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":1,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"parquet at treeModels.scala:491","dataWritten":3994184,"dataRead":0,"rowCount":62892,"usageDescription":"","jobId":66,"name":"parquet at treeModels.scala:491","description":"Job group for statement 10:\n# Test multiple regression models\n\nmodels = {\n    \"Linear Regression\": LinearRegression(),\n    \"Decision Tree\": DecisionTreeRegressor(),\n    \"Random Forest\": RandomForestRegressor(numTrees = 1000)\n}\n\nfor name, model in models.items():\n    train_evaluate(model, name, train_df, test_df)","submissionTime":"2023-09-08T13:50:41.611GMT","completionTime":"2023-09-08T13:50:41.908GMT","stageIds":[88],"jobGroup":"10","status":"SUCCEEDED","numTasks":8,"numActiveTasks":0,"numCompletedTasks":8,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":8,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"parquet at treeModels.scala:483","dataWritten":87590,"dataRead":86298,"rowCount":2000,"usageDescription":"","jobId":65,"name":"parquet at treeModels.scala:483","description":"Job group for statement 10:\n# Test multiple regression models\n\nmodels = {\n    \"Linear Regression\": LinearRegression(),\n    \"Decision Tree\": DecisionTreeRegressor(),\n    \"Random Forest\": RandomForestRegressor(numTrees = 1000)\n}\n\nfor name, model in models.items():\n    train_evaluate(model, name, train_df, test_df)","submissionTime":"2023-09-08T13:50:40.619GMT","completionTime":"2023-09-08T13:50:41.084GMT","stageIds":[86,87],"jobGroup":"10","status":"SUCCEEDED","numTasks":9,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":8,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":1,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"parquet at treeModels.scala:483","dataWritten":86298,"dataRead":0,"rowCount":1000,"usageDescription":"","jobId":64,"name":"parquet at treeModels.scala:483","description":"Job group for statement 10:\n# Test multiple regression models\n\nmodels = {\n    \"Linear Regression\": LinearRegression(),\n    \"Decision Tree\": DecisionTreeRegressor(),\n    \"Random Forest\": RandomForestRegressor(numTrees = 1000)\n}\n\nfor name, model in models.items():\n    train_evaluate(model, name, train_df, test_df)","submissionTime":"2023-09-08T13:50:40.548GMT","completionTime":"2023-09-08T13:50:40.586GMT","stageIds":[85],"jobGroup":"10","status":"SUCCEEDED","numTasks":8,"numActiveTasks":0,"numCompletedTasks":8,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":8,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"runJob at SparkHadoopWriter.scala:85","dataWritten":685,"dataRead":0,"rowCount":1,"usageDescription":"","jobId":63,"name":"runJob at SparkHadoopWriter.scala:85","description":"Job group for statement 10:\n# Test multiple regression models\n\nmodels = {\n    \"Linear Regression\": LinearRegression(),\n    \"Decision Tree\": DecisionTreeRegressor(),\n    \"Random Forest\": RandomForestRegressor(numTrees = 1000)\n}\n\nfor name, model in models.items():\n    train_evaluate(model, name, train_df, test_df)","submissionTime":"2023-09-08T13:50:39.638GMT","completionTime":"2023-09-08T13:50:40.017GMT","stageIds":[84],"jobGroup":"10","status":"SUCCEEDED","numTasks":1,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"runJob at SparkHadoopWriter.scala:85","dataWritten":228,"dataRead":0,"rowCount":1,"usageDescription":"","jobId":62,"name":"runJob at SparkHadoopWriter.scala:85","description":"Job group for statement 10:\n# Test multiple regression models\n\nmodels = {\n    \"Linear Regression\": LinearRegression(),\n    \"Decision Tree\": DecisionTreeRegressor(),\n    \"Random Forest\": RandomForestRegressor(numTrees = 1000)\n}\n\nfor name, model in models.items():\n    train_evaluate(model, name, train_df, test_df)","submissionTime":"2023-09-08T13:50:38.805GMT","completionTime":"2023-09-08T13:50:39.187GMT","stageIds":[83],"jobGroup":"10","status":"SUCCEEDED","numTasks":1,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"collect at /tmp/ipykernel_9563/850314080.py:34","dataWritten":0,"dataRead":8456428,"rowCount":313536,"usageDescription":"","jobId":61,"name":"collect at /tmp/ipykernel_9563/850314080.py:34","description":"Job group for statement 10:\n# Test multiple regression models\n\nmodels = {\n    \"Linear Regression\": LinearRegression(),\n    \"Decision Tree\": DecisionTreeRegressor(),\n    \"Random Forest\": RandomForestRegressor(numTrees = 1000)\n}\n\nfor name, model in models.items():\n    train_evaluate(model, name, train_df, test_df)","submissionTime":"2023-09-08T13:50:34.161GMT","completionTime":"2023-09-08T13:50:35.991GMT","stageIds":[82],"jobGroup":"10","status":"SUCCEEDED","numTasks":3,"numActiveTasks":0,"numCompletedTasks":3,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":3,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"collect at /tmp/ipykernel_9563/850314080.py:34","dataWritten":0,"dataRead":25315,"rowCount":0,"usageDescription":"","jobId":60,"name":"collect at /tmp/ipykernel_9563/850314080.py:34","description":"Job group for statement 10:\n# Test multiple regression models\n\nmodels = {\n    \"Linear Regression\": LinearRegression(),\n    \"Decision Tree\": DecisionTreeRegressor(),\n    \"Random Forest\": RandomForestRegressor(numTrees = 1000)\n}\n\nfor name, model in models.items():\n    train_evaluate(model, name, train_df, test_df)","submissionTime":"2023-09-08T13:50:34.075GMT","completionTime":"2023-09-08T13:50:34.157GMT","stageIds":[81],"jobGroup":"10","status":"SUCCEEDED","numTasks":1,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"collect at /tmp/ipykernel_9563/850314080.py:33","dataWritten":0,"dataRead":8456428,"rowCount":313536,"usageDescription":"","jobId":59,"name":"collect at /tmp/ipykernel_9563/850314080.py:33","description":"Job group for statement 10:\n# Test multiple regression models\n\nmodels = {\n    \"Linear Regression\": LinearRegression(),\n    \"Decision Tree\": DecisionTreeRegressor(),\n    \"Random Forest\": RandomForestRegressor(numTrees = 1000)\n}\n\nfor name, model in models.items():\n    train_evaluate(model, name, train_df, test_df)","submissionTime":"2023-09-08T13:50:32.173GMT","completionTime":"2023-09-08T13:50:33.999GMT","stageIds":[80],"jobGroup":"10","status":"SUCCEEDED","numTasks":3,"numActiveTasks":0,"numCompletedTasks":3,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":3,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"collect at /tmp/ipykernel_9563/850314080.py:33","dataWritten":0,"dataRead":25315,"rowCount":0,"usageDescription":"","jobId":58,"name":"collect at /tmp/ipykernel_9563/850314080.py:33","description":"Job group for statement 10:\n# Test multiple regression models\n\nmodels = {\n    \"Linear Regression\": LinearRegression(),\n    \"Decision Tree\": DecisionTreeRegressor(),\n    \"Random Forest\": RandomForestRegressor(numTrees = 1000)\n}\n\nfor name, model in models.items():\n    train_evaluate(model, name, train_df, test_df)","submissionTime":"2023-09-08T13:50:31.987GMT","completionTime":"2023-09-08T13:50:32.169GMT","stageIds":[79],"jobGroup":"10","status":"SUCCEEDED","numTasks":1,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"treeAggregate at Statistics.scala:58","dataWritten":0,"dataRead":8481743,"rowCount":313536,"usageDescription":"","jobId":57,"name":"treeAggregate at Statistics.scala:58","description":"Job group for statement 10:\n# Test multiple regression models\n\nmodels = {\n    \"Linear Regression\": LinearRegression(),\n    \"Decision Tree\": DecisionTreeRegressor(),\n    \"Random Forest\": RandomForestRegressor(numTrees = 1000)\n}\n\nfor name, model in models.items():\n    train_evaluate(model, name, train_df, test_df)","submissionTime":"2023-09-08T13:50:21.491GMT","completionTime":"2023-09-08T13:50:31.854GMT","stageIds":[78],"jobGroup":"10","status":"SUCCEEDED","numTasks":4,"numActiveTasks":0,"numCompletedTasks":4,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":4,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"treeAggregate at Statistics.scala:58","dataWritten":0,"dataRead":8481743,"rowCount":313536,"usageDescription":"","jobId":56,"name":"treeAggregate at Statistics.scala:58","description":"Job group for statement 10:\n# Test multiple regression models\n\nmodels = {\n    \"Linear Regression\": LinearRegression(),\n    \"Decision Tree\": DecisionTreeRegressor(),\n    \"Random Forest\": RandomForestRegressor(numTrees = 1000)\n}\n\nfor name, model in models.items():\n    train_evaluate(model, name, train_df, test_df)","submissionTime":"2023-09-08T13:50:09.447GMT","completionTime":"2023-09-08T13:50:21.387GMT","stageIds":[77],"jobGroup":"10","status":"SUCCEEDED","numTasks":4,"numActiveTasks":0,"numCompletedTasks":4,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":4,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"collectAsMap at RandomForest.scala:663","dataWritten":74588373,"dataRead":904141533,"rowCount":314225,"usageDescription":"","jobId":55,"name":"collectAsMap at RandomForest.scala:663","description":"Job group for statement 10:\n# Test multiple regression models\n\nmodels = {\n    \"Linear Regression\": LinearRegression(),\n    \"Decision Tree\": DecisionTreeRegressor(),\n    \"Random Forest\": RandomForestRegressor(numTrees = 1000)\n}\n\nfor name, model in models.items():\n    train_evaluate(model, name, train_df, test_df)","submissionTime":"2023-09-08T13:48:54.021GMT","completionTime":"2023-09-08T13:50:07.960GMT","stageIds":[75,76],"jobGroup":"10","status":"SUCCEEDED","numTasks":8,"numActiveTasks":0,"numCompletedTasks":8,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":8,"numActiveStages":0,"numCompletedStages":2,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"collectAsMap at RandomForest.scala:663","dataWritten":42566379,"dataRead":872119539,"rowCount":250617,"usageDescription":"","jobId":54,"name":"collectAsMap at RandomForest.scala:663","description":"Job group for statement 10:\n# Test multiple regression models\n\nmodels = {\n    \"Linear Regression\": LinearRegression(),\n    \"Decision Tree\": DecisionTreeRegressor(),\n    \"Random Forest\": RandomForestRegressor(numTrees = 1000)\n}\n\nfor name, model in models.items():\n    train_evaluate(model, name, train_df, test_df)","submissionTime":"2023-09-08T13:48:02.589GMT","completionTime":"2023-09-08T13:48:53.737GMT","stageIds":[74,73],"jobGroup":"10","status":"SUCCEEDED","numTasks":8,"numActiveTasks":0,"numCompletedTasks":8,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":8,"numActiveStages":0,"numCompletedStages":2,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"collectAsMap at RandomForest.scala:663","dataWritten":23826204,"dataRead":853379364,"rowCount":218633,"usageDescription":"","jobId":53,"name":"collectAsMap at RandomForest.scala:663","description":"Job group for statement 10:\n# Test multiple regression models\n\nmodels = {\n    \"Linear Regression\": LinearRegression(),\n    \"Decision Tree\": DecisionTreeRegressor(),\n    \"Random Forest\": RandomForestRegressor(numTrees = 1000)\n}\n\nfor name, model in models.items():\n    train_evaluate(model, name, train_df, test_df)","submissionTime":"2023-09-08T13:47:20.762GMT","completionTime":"2023-09-08T13:48:02.444GMT","stageIds":[71,72],"jobGroup":"10","status":"SUCCEEDED","numTasks":8,"numActiveTasks":0,"numCompletedTasks":8,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":8,"numActiveStages":0,"numCompletedStages":2,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"collectAsMap at RandomForest.scala:663","dataWritten":13170104,"dataRead":842723264,"rowCount":202633,"usageDescription":"","jobId":52,"name":"collectAsMap at RandomForest.scala:663","description":"Job group for statement 10:\n# Test multiple regression models\n\nmodels = {\n    \"Linear Regression\": LinearRegression(),\n    \"Decision Tree\": DecisionTreeRegressor(),\n    \"Random Forest\": RandomForestRegressor(numTrees = 1000)\n}\n\nfor name, model in models.items():\n    train_evaluate(model, name, train_df, test_df)","submissionTime":"2023-09-08T13:46:51.532GMT","completionTime":"2023-09-08T13:47:20.627GMT","stageIds":[70,69],"jobGroup":"10","status":"SUCCEEDED","numTasks":8,"numActiveTasks":0,"numCompletedTasks":8,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":8,"numActiveStages":0,"numCompletedStages":2,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"collectAsMap at RandomForest.scala:663","dataWritten":7275469,"dataRead":15757212,"rowCount":321536,"usageDescription":"","jobId":51,"name":"collectAsMap at RandomForest.scala:663","description":"Job group for statement 10:\n# Test multiple regression models\n\nmodels = {\n    \"Linear Regression\": LinearRegression(),\n    \"Decision Tree\": DecisionTreeRegressor(),\n    \"Random Forest\": RandomForestRegressor(numTrees = 1000)\n}\n\nfor name, model in models.items():\n    train_evaluate(model, name, train_df, test_df)","submissionTime":"2023-09-08T13:46:17.277GMT","completionTime":"2023-09-08T13:46:51.434GMT","stageIds":[67,68],"jobGroup":"10","status":"SUCCEEDED","numTasks":8,"numActiveTasks":0,"numCompletedTasks":8,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":8,"numActiveStages":0,"numCompletedStages":2,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"collectAsMap at RandomForest.scala:1054","dataWritten":309056,"dataRead":8790799,"rowCount":313776,"usageDescription":"","jobId":50,"name":"collectAsMap at RandomForest.scala:1054","description":"Job group for statement 10:\n# Test multiple regression models\n\nmodels = {\n    \"Linear Regression\": LinearRegression(),\n    \"Decision Tree\": DecisionTreeRegressor(),\n    \"Random Forest\": RandomForestRegressor(numTrees = 1000)\n}\n\nfor name, model in models.items():\n    train_evaluate(model, name, train_df, test_df)","submissionTime":"2023-09-08T13:46:14.192GMT","completionTime":"2023-09-08T13:46:17.203GMT","stageIds":[66,65],"jobGroup":"10","status":"SUCCEEDED","numTasks":8,"numActiveTasks":0,"numCompletedTasks":8,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":8,"numActiveStages":0,"numCompletedStages":2,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"aggregate at DecisionTreeMetadata.scala:125","dataWritten":0,"dataRead":8481743,"rowCount":313536,"usageDescription":"","jobId":49,"name":"aggregate at DecisionTreeMetadata.scala:125","description":"Job group for statement 10:\n# Test multiple regression models\n\nmodels = {\n    \"Linear Regression\": LinearRegression(),\n    \"Decision Tree\": DecisionTreeRegressor(),\n    \"Random Forest\": RandomForestRegressor(numTrees = 1000)\n}\n\nfor name, model in models.items():\n    train_evaluate(model, name, train_df, test_df)","submissionTime":"2023-09-08T13:46:11.239GMT","completionTime":"2023-09-08T13:46:14.175GMT","stageIds":[64],"jobGroup":"10","status":"SUCCEEDED","numTasks":4,"numActiveTasks":0,"numCompletedTasks":4,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":4,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"take at DecisionTreeMetadata.scala:119","dataWritten":0,"dataRead":8456428,"rowCount":313536,"usageDescription":"","jobId":48,"name":"take at DecisionTreeMetadata.scala:119","description":"Job group for statement 10:\n# Test multiple regression models\n\nmodels = {\n    \"Linear Regression\": LinearRegression(),\n    \"Decision Tree\": DecisionTreeRegressor(),\n    \"Random Forest\": RandomForestRegressor(numTrees = 1000)\n}\n\nfor name, model in models.items():\n    train_evaluate(model, name, train_df, test_df)","submissionTime":"2023-09-08T13:46:09.591GMT","completionTime":"2023-09-08T13:46:11.234GMT","stageIds":[63],"jobGroup":"10","status":"SUCCEEDED","numTasks":3,"numActiveTasks":0,"numCompletedTasks":3,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":3,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}}],"limit":20,"rule":"ALL_DESC"},"parent_msg_id":"599446a0-43ca-4ec4-bbf3-569766fd40c5"},"text/plain":"StatementMeta(, f29bf580-53de-48f1-a7c1-2dc479c0524f, 10, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["[[ 73.44974366  42.        ]\n [ 90.22275998  76.        ]\n [ 74.45575443  55.        ]\n [-12.082187    28.        ]\n [ 97.12712308  30.        ]\n [ 97.01676881  35.        ]\n [ 94.49072732  76.        ]\n [  9.74574921  50.        ]\n [ 94.29745068  40.        ]\n [ 87.62425004  95.        ]\n [ 15.15980688  44.        ]\n [ 67.97486533  60.        ]\n [ 98.90566625  30.        ]\n [  8.59555472  99.        ]\n [ 46.68746299 149.        ]\n [ 15.67566958  60.        ]\n [ 95.12875765  55.        ]\n [ 12.75488982  30.        ]\n [105.27492839  45.        ]\n [  0.57401764  48.        ]\n [100.51081239  60.        ]\n [ 74.55361061  37.        ]\n [ 66.60124427  75.        ]\n [ 44.51344898  55.        ]\n [ 83.74016356  45.        ]\n [106.05530496  66.        ]\n [ 70.39531747  32.        ]\n [ 70.39531747  32.        ]\n [-12.5699937   18.        ]\n [ 90.26743225  59.        ]\n [104.2098675   39.        ]\n [106.54758821  69.        ]\n [106.54758821  69.        ]\n [106.54758821  69.        ]\n [ 96.55528533  56.        ]\n [ 57.32277579  50.        ]\n [141.95425227  80.        ]\n [141.95425227  80.        ]\n [ 61.94703559  35.        ]\n [ 42.57257781  50.        ]\n [136.19432277  60.        ]\n [136.19432277  60.        ]\n [ 81.17928268  39.        ]\n [ 64.4690743   41.        ]\n [ 77.70052621  45.        ]\n [ 11.68225183  50.        ]\n [ 95.97130606  91.        ]\n [ 62.1109788   35.        ]\n [ 50.077934    30.        ]\n [ 29.45575627  16.        ]\n [ 58.40983208  22.        ]\n [103.97601064  92.        ]\n [146.53185229  95.        ]\n [ 69.16318221  26.        ]\n [ 54.14524921  25.        ]\n [ 54.14524921  25.        ]\n [ 97.02148948  55.        ]\n [ 66.50676781  35.        ]\n [ 66.50676781  35.        ]\n [105.02612984  41.        ]\n [ 53.82135083 298.        ]\n [ 58.65992535  40.        ]\n [ 77.79191533 371.        ]\n [ 83.18677687  17.        ]\n [ 83.06019957 100.        ]\n [ 74.85032566 192.        ]\n [ 69.71060575  25.        ]\n [ 56.49566859  45.        ]\n [117.83531229  50.        ]\n [ 58.03314475  22.        ]\n [ 12.09829685  25.        ]\n [ 67.94248221  23.        ]\n [ 74.90475152 351.        ]\n [ 52.17826995  18.        ]\n [106.50897004  43.        ]\n [ 30.05386219  30.        ]\n [ 60.59571553  35.        ]\n [ 95.23838858  45.        ]\n [ 58.89362367 245.        ]\n [117.57147204  69.        ]\n [ 96.01458845  39.        ]\n [ 74.90935788  80.        ]\n [ 79.27676594  65.        ]\n [ 48.07268806  40.        ]\n [ 81.03524132  30.        ]\n [ 94.71915426  50.        ]\n [ 94.71915426  50.        ]\n [117.62176479  42.        ]\n [ 88.26307841  64.        ]\n [146.55094771  28.        ]\n [ 82.35222191  19.        ]\n [ 97.67529936  74.        ]\n [ 97.67529936  74.        ]\n [101.04993255 149.        ]\n [ 49.66394154 100.        ]\n [ 55.04325413  43.        ]\n [ 55.04325413  43.        ]\n [ 81.87984918  55.        ]\n [100.48586985  97.        ]\n [128.36063602  50.        ]]\nModel saved in run_id=cb153a02-00e4-4704-a07f-d2fb882cc00f\nLinear Regression MSE: 17672.06259206297\n[[ 77.67019345  42.        ]\n [143.36372996  76.        ]\n [ 77.67019345  55.        ]\n [ 51.01825791  28.        ]\n [ 79.72752352  30.        ]\n [ 79.72752352  35.        ]\n [ 79.72752352  76.        ]\n [ 77.67019345  50.        ]\n [ 79.72752352  40.        ]\n [143.36372996  95.        ]\n [ 77.67019345  44.        ]\n [143.36372996  60.        ]\n [ 79.72752352  30.        ]\n [ 77.67019345  99.        ]\n [ 77.67019345 149.        ]\n [ 77.67019345  60.        ]\n [ 79.72752352  55.        ]\n [ 51.01825791  30.        ]\n [ 79.72752352  45.        ]\n [ 77.67019345  48.        ]\n [ 77.67019345  60.        ]\n [ 82.14559737  37.        ]\n [ 77.67019345  75.        ]\n [ 77.67019345  55.        ]\n [ 77.67019345  45.        ]\n [ 77.67019345  66.        ]\n [ 51.01825791  32.        ]\n [ 51.01825791  32.        ]\n [ 51.01825791  18.        ]\n [ 77.67019345  59.        ]\n [ 77.67019345  39.        ]\n [ 77.67019345  69.        ]\n [ 77.67019345  69.        ]\n [ 77.67019345  69.        ]\n [ 77.67019345  56.        ]\n [ 77.67019345  50.        ]\n [ 79.72752352  80.        ]\n [ 79.72752352  80.        ]\n [ 77.67019345  35.        ]\n [ 77.67019345  50.        ]\n [143.36372996  60.        ]\n [143.36372996  60.        ]\n [ 77.67019345  39.        ]\n [ 77.67019345  41.        ]\n [ 51.01825791  45.        ]\n [ 69.19047619  50.        ]\n [ 77.67019345  91.        ]\n [ 77.67019345  35.        ]\n [ 77.67019345  30.        ]\n [ 82.14559737  16.        ]\n [ 51.01825791  22.        ]\n [ 77.67019345  92.        ]\n [143.36372996  95.        ]\n [ 51.01825791  26.        ]\n [ 77.67019345  25.        ]\n [ 77.67019345  25.        ]\n [ 77.67019345  55.        ]\n [ 51.01825791  35.        ]\n [ 51.01825791  35.        ]\n [ 77.67019345  41.        ]\n [572.47401472 298.        ]\n [ 51.01825791  40.        ]\n [ 77.67019345 371.        ]\n [ 51.01825791  17.        ]\n [ 77.67019345 100.        ]\n [572.47401472 192.        ]\n [ 51.01825791  25.        ]\n [ 77.67019345  45.        ]\n [ 77.67019345  50.        ]\n [ 51.01825791  22.        ]\n [ 77.67019345  25.        ]\n [ 51.01825791  23.        ]\n [572.47401472 351.        ]\n [ 77.67019345  18.        ]\n [ 77.67019345  43.        ]\n [ 69.19047619  30.        ]\n [ 51.01825791  35.        ]\n [ 77.67019345  45.        ]\n [572.47401472 245.        ]\n [ 77.67019345  69.        ]\n [ 77.67019345  39.        ]\n [ 82.14559737  80.        ]\n [ 82.14559737  65.        ]\n [ 77.67019345  40.        ]\n [ 51.01825791  30.        ]\n [ 51.01825791  50.        ]\n [ 51.01825791  50.        ]\n [ 77.67019345  42.        ]\n [ 77.67019345  64.        ]\n [ 79.72752352  28.        ]\n [ 51.01825791  19.        ]\n [ 77.67019345  74.        ]\n [ 77.67019345  74.        ]\n [ 77.67019345 149.        ]\n [ 77.67019345 100.        ]\n [ 51.01825791  43.        ]\n [ 51.01825791  43.        ]\n [ 77.67019345  55.        ]\n [ 77.67019345  97.        ]\n [143.36372996  50.        ]]\nModel saved in run_id=614cea13-1a49-4010-8a96-66471d831c89\nDecision Tree MSE: 8796.90918281521\n[[101.29413063  42.        ]\n [133.3899724   76.        ]\n [111.05938343  55.        ]\n [ 67.61607065  28.        ]\n [104.22569512  30.        ]\n [ 86.80394613  35.        ]\n [ 86.66204593  76.        ]\n [ 79.78722953  50.        ]\n [ 86.70357218  40.        ]\n [133.79347394  95.        ]\n [ 80.44454091  44.        ]\n [133.50941871  60.        ]\n [ 86.53703809  30.        ]\n [ 77.28727682  99.        ]\n [ 98.46730239 149.        ]\n [ 80.56066822  60.        ]\n [ 86.5539235   55.        ]\n [ 57.42597047  30.        ]\n [ 86.8735067   45.        ]\n [ 77.35823581  48.        ]\n [108.38435225  60.        ]\n [ 73.34497433  37.        ]\n [ 74.81118426  75.        ]\n [ 75.82101891  55.        ]\n [102.54871463  45.        ]\n [108.9836172   66.        ]\n [ 57.67536772  32.        ]\n [ 57.67536772  32.        ]\n [ 66.67961401  18.        ]\n [108.58080223  59.        ]\n [102.00433434  39.        ]\n [ 99.83007591  69.        ]\n [ 99.83007591  69.        ]\n [ 99.83007591  69.        ]\n [111.19186476  56.        ]\n [ 76.99102641  50.        ]\n [ 88.91204267  80.        ]\n [ 88.91204267  80.        ]\n [ 80.33780552  35.        ]\n [ 73.40076696  50.        ]\n [134.37510255  60.        ]\n [134.37510255  60.        ]\n [102.21992011  39.        ]\n [ 78.97948727  41.        ]\n [ 57.0463092   45.        ]\n [110.33623222  50.        ]\n [108.5775226   91.        ]\n [ 73.36661347  35.        ]\n [127.63254177  30.        ]\n [ 73.01989641  16.        ]\n [ 57.00959035  22.        ]\n [108.69629927  92.        ]\n [136.0516661   95.        ]\n [ 56.8302269   26.        ]\n [ 92.6235583   25.        ]\n [ 92.6235583   25.        ]\n [111.46388499  55.        ]\n [ 57.21291512  35.        ]\n [ 57.21291512  35.        ]\n [110.76297529  41.        ]\n [290.34744148 298.        ]\n [ 57.32345378  40.        ]\n [257.53078831 371.        ]\n [ 68.07259368  17.        ]\n [111.81997528 100.        ]\n [286.56969682 192.        ]\n [ 56.90139495  25.        ]\n [ 74.18884856  45.        ]\n [108.89724069  50.        ]\n [ 56.45283509  22.        ]\n [ 83.97893446  25.        ]\n [ 56.99823593  23.        ]\n [291.16860031 351.        ]\n [124.79395244  18.        ]\n [108.33654849  43.        ]\n [110.40496534  30.        ]\n [ 56.96174557  35.        ]\n [111.47853108  45.        ]\n [289.22692489 245.        ]\n [110.61036587  69.        ]\n [101.52068517  39.        ]\n [ 86.86171086  80.        ]\n [ 73.6654688   65.        ]\n [ 78.38435782  40.        ]\n [ 57.34468481  30.        ]\n [ 60.68722312  50.        ]\n [ 60.68722312  50.        ]\n [ 99.70809029  42.        ]\n [105.47383061  64.        ]\n [ 88.96077413  28.        ]\n [ 56.96595995  19.        ]\n [102.42146621  74.        ]\n [102.42146621  74.        ]\n [108.91706485 149.        ]\n [ 78.8237106  100.        ]\n [ 72.83878434  43.        ]\n [ 72.83878434  43.        ]\n [ 78.53967672  55.        ]\n [101.80398422  97.        ]\n [131.07164843  50.        ]]\nModel saved in run_id=14dc5cfb-03b4-4eb7-9ea1-544452ceb1f7\nRandom Forest MSE: 8334.988116310811\n"]},{"output_type":"stream","name":"stderr","text":["2023/09/08 13:45:29 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpa2diattc/model, flavor: spark), fall back to return ['pyspark==3.3.1']. Set logging level to DEBUG to see the full traceback.\n/home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n  warnings.warn(\"Setuptools is replacing distutils.\")\n2023/09/08 13:46:04 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpjf3xnda8/model, flavor: spark), fall back to return ['pyspark==3.3.1']. Set logging level to DEBUG to see the full traceback.\n2023/09/08 13:50:46 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpbxb4ns1e/model, flavor: spark), fall back to return ['pyspark==3.3.1']. Set logging level to DEBUG to see the full traceback.\n"]}],"execution_count":8,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"0d40797a-180f-4c6a-bd66-8ee91bcc3301"},{"cell_type":"markdown","source":["#### Train a neural net\n","\n","In the same experiment we would like to compare the performance of the Machine Learning algorithms from the MLLib library with a Pytorch neural net"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"424c5e56-b5ab-4795-8e2b-02802a9df9f9"},{"cell_type":"markdown","source":["#### Step 1: Create neural net architecture for regression"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"7d7c949f-c323-4224-ab83-028ea7e9a99c"},{"cell_type":"code","source":["# 1. Create MLP class\n","\n","\n","class MLP(nn.Module):\n","    def __init__(self, input_dim, l1_neurons, l2_neurons):\n","        super(MLP, self).__init__()\n","        self.layer1 = nn.Linear(input_dim, l1_neurons)\n","        self.relu1 = nn.ReLU()\n","        self.layer2 = nn.Linear(l1_neurons, l2_neurons)\n","        self.relu2 = nn.ReLU()\n","        self.layer3 = nn.Linear(l2_neurons, 1)  \n","\n","        self._initialize_weights()\n","\n","    def _initialize_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Linear):\n","                init.kaiming_uniform_(m.weight, nonlinearity='relu')\n","                if m.bias is not None: # Check if bias exists before initializing\n","                    init.constant_(m.bias, 0)\n","    \n","    def forward(self, x):\n","        x = self.layer1(x)\n","        x = self.relu1(x)\n","        x = self.layer2(x)\n","        x = self.relu2(x)\n","        x = self.layer3(x)\n","        \n","        return x"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"f29bf580-53de-48f1-a7c1-2dc479c0524f","statement_id":11,"state":"finished","livy_statement_state":"available","queued_time":"2023-09-08T13:49:31.0035001Z","session_start_time":null,"execution_start_time":"2023-09-08T13:50:51.115947Z","execution_finish_time":"2023-09-08T13:50:51.410493Z","spark_jobs":{"numbers":{"FAILED":0,"RUNNING":0,"SUCCEEDED":0,"UNKNOWN":0},"jobs":[],"limit":20,"rule":"ALL_DESC"},"parent_msg_id":"b03bbd84-890b-4e9d-96d7-b5378014f7fa"},"text/plain":"StatementMeta(, f29bf580-53de-48f1-a7c1-2dc479c0524f, 11, Finished, Available)"},"metadata":{}}],"execution_count":9,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"45ad485e-913b-4438-a7c0-1314198483fa"},{"cell_type":"markdown","source":["#### Step 2: Create ML FLow experiment function"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"e429dfbc-bbd6-46c6-91c3-ef5f827654b4"},{"cell_type":"code","source":["# Generate function in which Ml Flow experiment is kicked off\n","from mlflow.models.signature import infer_signature\n","import numpy as np\n","\n","def train_evaluate(input_dim, batchsize, learning_rate,\n","                num_epochs, train_df, test_x, test_y,\n","                l1_neurons, l2_neurons):\n","    with mlflow.start_run(run_name=\"mlp_regression\") as run:\n","        # Log model parameters\n","        mlflow.log_param(\"num_training_rows\", len(train_df))\n","        mlflow.log_param(\"batch size\", batchsize)\n","        mlflow.log_param(\"learning rate\", learning_rate)\n","        mlflow.log_param(\"num_epochs\", num_epochs)\n","        \n","        # Activate dataloader\n","        dataloader = DataLoader(train_df, batch_size=batchsize, shuffle=True)\n","        \n","        # Initialize model, loss and optimizer\n","        model = MLP(input_dim=input_dim, l1_neurons=l1_neurons, l2_neurons=l2_neurons)\n","        criterion = nn.MSELoss()\n","        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","        \n","        # Execute model training\n","        for epoch in range(num_epochs):\n","            for batch_x, batch_y in dataloader:\n","                # Forward pass\n","                outputs = model.forward(batch_x)\n","                outputs = outputs.squeeze(1)\n","                loss = criterion(outputs, batch_y)\n","                \n","                # Backward pass and optimization\n","                optimizer.zero_grad()\n","                loss.backward()\n","                optimizer.step()\n","            \n","        \n","        # Make predictions\n","        predictions = model(test_x)\n","\n","        # Calculate MSE and MAE\n","        mse_loss = nn.MSELoss()\n","        #mae_loss = nn.L1Loss() \n","\n","        mse = mse_loss(predictions, test_y)\n","        #mae = mae_loss(predictions, test_y)\n"," \n","        #Store artifacts\n","        pred_array = predictions[:100].detach().numpy().flatten()\n","        truth_array = test_y[:100].detach().numpy().flatten()\n","        \n","        # Combine predictions and ground truth into a single array\n","        combined_array = np.stack((pred_array, truth_array), axis=-1)\n","        print(combined_array)\n","\n","        # Save them to a .npy file\n","        np.save(\"combined_predictions_truth.npy\", combined_array)\n","        \n","        # Log the combined numpy array as an artifact\n","        mlflow.log_artifact(\"combined_predictions_truth.npy\")\n","        # Log metrics\n","        mlflow.log_metric(\"mse\", mse)\n","        #mlflow.log_metric(\"mae\", mae)\n","\n","        mlflow.pytorch.log_model(model, \"price_predictions_airbnb_mlp\")\n","        print(\"Model saved in run_id=%s\" % run.info.run_id)\n","        artifact_uri = mlflow.get_artifact_uri(\"model\")\n","        print(artifact_uri)\n","\n","        #mlflow.register_model(\n","        #\"runs:/{}/price_predictions_airbnb\".format(run.info.run_id), name)\n","        \n","        print(f\"\"\"Neural Net parameters:\n","                  batchsize: {batchsize} \\n\n","                  learning_rate: {learning_rate} \\n\n","                  num_epochs: {num_epochs} \\n\n","                  Neurons: {l1_neurons} l2_neurons \\n\n","                  MSE: {mse}\"\"\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"f29bf580-53de-48f1-a7c1-2dc479c0524f","statement_id":12,"state":"finished","livy_statement_state":"available","queued_time":"2023-09-08T13:51:25.7318494Z","session_start_time":null,"execution_start_time":"2023-09-08T13:51:26.1871473Z","execution_finish_time":"2023-09-08T13:51:26.4947493Z","spark_jobs":{"numbers":{"FAILED":0,"RUNNING":0,"SUCCEEDED":0,"UNKNOWN":0},"jobs":[],"limit":20,"rule":"ALL_DESC"},"parent_msg_id":"575ee3bd-fd30-4cbd-aa79-e53d0bde705b"},"text/plain":"StatementMeta(, f29bf580-53de-48f1-a7c1-2dc479c0524f, 12, Finished, Available)"},"metadata":{}}],"execution_count":10,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"bd1f2afc-ff72-4578-832e-71c3e8cd0fd3"},{"cell_type":"markdown","source":["#### Step 3: Prepare data for pytorch"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"bcd642a4-b155-42d6-9869-e4d7e35612a9"},{"cell_type":"code","source":["# Convert the PySpark DataFrame to Pandas DataFrame\n","pandas_train_df = train_df.drop(\"features\").toPandas()\n","pandas_test_df = test_df.drop(\"features\").toPandas()\n","\n","# Split train in x and y\n","train_x = torch.from_numpy(pandas_train_df.drop(\"price\", axis = 1).values).to(torch.float32)\n","train_y = torch.from_numpy(pandas_train_df[\"price\"].values).to(torch.float32)\n","dataset_train = TensorDataset(train_x, train_y)\n","\n","# Split test in x and y\n","test_x = torch.from_numpy(pandas_test_df.drop(\"price\", axis = 1).values).to(torch.float32)\n","test_y = torch.from_numpy(pandas_test_df[\"price\"].values).to(torch.float32).to(torch.float32)\n","\n","\n","print(train_x.shape)\n","# # Assemble the features into a single vector\n","# vector_assembler = VectorAssembler(inputCols=data.feature_names, outputCol=\"features\")\n","# train_df = vector_assembler.transform(train_df)\n","# test_df = vector_assembler.transform(test_df)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"f29bf580-53de-48f1-a7c1-2dc479c0524f","statement_id":17,"state":"finished","livy_statement_state":"available","queued_time":"2023-09-08T14:01:19.8582389Z","session_start_time":null,"execution_start_time":"2023-09-08T14:01:20.3145985Z","execution_finish_time":"2023-09-08T14:01:28.4334769Z","spark_jobs":{"numbers":{"FAILED":0,"RUNNING":0,"SUCCEEDED":2,"UNKNOWN":0},"jobs":[{"displayName":"toPandas at /tmp/ipykernel_9563/40899727.py:3","dataWritten":0,"dataRead":8481743,"rowCount":313536,"usageDescription":"","jobId":71,"name":"toPandas at /tmp/ipykernel_9563/40899727.py:3","description":"Job group for statement 17:\n# Convert the PySpark DataFrame to Pandas DataFrame\npandas_train_df = train_df.drop(\"features\").toPandas()\npandas_test_df = test_df.drop(\"features\").toPandas()\n\n# Split train in x and y\ntrain_x = torch.from_numpy(pandas_train_df.drop(\"price\", axis = 1).values).to(torch.float32)\ntrain_y = torch.from_numpy(pandas_train_df[\"price\"].values).to(torch.float32)\ndataset_train = TensorDataset(train_x, train_y)\n\n# Split test in x and y\ntest_x = torch.from_numpy(pandas_test_df.drop(\"price\", axis = 1).values).to(torch.float32)\ntest_y = torch.from_numpy(pandas_test_df[\"price\"].values).to(torch.float32).to(torch.float32)\n\n\nprint(train_x.shape)\n# # Assemble the features into a single vector\n# vector_assembler = VectorAssembler(inputCols=data.feature_names, outputCol=\"features\")\n# train_df = vector_assembler.transform(train_df)\n# test_df = vector_assembler.transform(test_df)","submissionTime":"2023-09-08T14:01:24.122GMT","completionTime":"2023-09-08T14:01:26.875GMT","stageIds":[94],"jobGroup":"17","status":"SUCCEEDED","numTasks":4,"numActiveTasks":0,"numCompletedTasks":4,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":4,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"toPandas at /tmp/ipykernel_9563/40899727.py:2","dataWritten":0,"dataRead":8481743,"rowCount":313536,"usageDescription":"","jobId":70,"name":"toPandas at /tmp/ipykernel_9563/40899727.py:2","description":"Job group for statement 17:\n# Convert the PySpark DataFrame to Pandas DataFrame\npandas_train_df = train_df.drop(\"features\").toPandas()\npandas_test_df = test_df.drop(\"features\").toPandas()\n\n# Split train in x and y\ntrain_x = torch.from_numpy(pandas_train_df.drop(\"price\", axis = 1).values).to(torch.float32)\ntrain_y = torch.from_numpy(pandas_train_df[\"price\"].values).to(torch.float32)\ndataset_train = TensorDataset(train_x, train_y)\n\n# Split test in x and y\ntest_x = torch.from_numpy(pandas_test_df.drop(\"price\", axis = 1).values).to(torch.float32)\ntest_y = torch.from_numpy(pandas_test_df[\"price\"].values).to(torch.float32).to(torch.float32)\n\n\nprint(train_x.shape)\n# # Assemble the features into a single vector\n# vector_assembler = VectorAssembler(inputCols=data.feature_names, outputCol=\"features\")\n# train_df = vector_assembler.transform(train_df)\n# test_df = vector_assembler.transform(test_df)","submissionTime":"2023-09-08T14:01:20.478GMT","completionTime":"2023-09-08T14:01:23.871GMT","stageIds":[93],"jobGroup":"17","status":"SUCCEEDED","numTasks":4,"numActiveTasks":0,"numCompletedTasks":4,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":4,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}}],"limit":20,"rule":"ALL_DESC"},"parent_msg_id":"e449aa3b-5f21-44c0-bced-469ae00aa068"},"text/plain":"StatementMeta(, f29bf580-53de-48f1-a7c1-2dc479c0524f, 17, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["torch.Size([186633, 78])\n"]}],"execution_count":15,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"6c592515-ac13-4da3-ada0-625386f74094"},{"cell_type":"code","source":["# Perform sanity checks\n","\n","# Check for nan values\n","has_nan = torch.isnan(train_x).any()\n","print(f\"Contains NaN values: {has_nan.item()}\")\n","\n","# Check for inf values\n","has_inf = torch.isinf(train_x).any()\n","print(f\"Contains Inf values: {has_inf.item()}\")\n","\n","nan_count = torch.sum(torch.isnan(train_x)).item()\n","print(f\"Number of NaN values: {nan_count}\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"f29bf580-53de-48f1-a7c1-2dc479c0524f","statement_id":18,"state":"finished","livy_statement_state":"available","queued_time":"2023-09-08T14:01:37.9174413Z","session_start_time":null,"execution_start_time":"2023-09-08T14:01:38.3282223Z","execution_finish_time":"2023-09-08T14:01:39.2071082Z","spark_jobs":{"numbers":{"FAILED":0,"RUNNING":0,"SUCCEEDED":0,"UNKNOWN":0},"jobs":[],"limit":20,"rule":"ALL_DESC"},"parent_msg_id":"3ca16d94-3c43-408b-8b41-bd2cd02261e7"},"text/plain":"StatementMeta(, f29bf580-53de-48f1-a7c1-2dc479c0524f, 18, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Contains NaN values: False\nContains Inf values: False\nNumber of NaN values: 0\n"]}],"execution_count":16,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"b4963f6b-8623-4659-a438-67c9850ece67"},{"cell_type":"markdown","source":[],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"20a02d56-3098-44b3-9ef5-8705a3134e5c"},{"cell_type":"markdown","source":["#### Step 4: Run multiple combinations of hyperparameters"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"f9d8c40e-fb6d-4ffa-b2ef-693ddd06840e"},{"cell_type":"code","source":["# Test multiple hyperparameters\n","\n","import itertools\n","\n","learning_rates = [ 0.1, 0.01, 0.001]\n","epochs = [100]\n","batch_sizes = [32, 64]\n","neurons = [32, 64]\n","\n","# Get all combinations\n","combinations = list(itertools.product(learning_rates, epochs, batch_sizes, neurons))\n","\n","for combo in combinations:\n","    learning_rate, epochs, batch_size, neuron = combo\n","    train_evaluate(78, batch_size, learning_rate,\n","                epochs, dataset_train, test_x, test_y,\n","                neuron, neuron)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"f29bf580-53de-48f1-a7c1-2dc479c0524f","statement_id":19,"state":"submitted","livy_statement_state":"running","queued_time":"2023-09-08T14:03:06.6351845Z","session_start_time":null,"execution_start_time":"2023-09-08T14:03:07.1803718Z","execution_finish_time":null,"spark_jobs":{"numbers":{"FAILED":0,"RUNNING":0,"SUCCEEDED":0,"UNKNOWN":0},"jobs":[],"limit":20,"rule":"ALL_DESC"},"parent_msg_id":"fc8d7203-3ccc-4a63-bba6-3c555fa119f7"},"text/plain":"StatementMeta(, f29bf580-53de-48f1-a7c1-2dc479c0524f, 19, Submitted, Running)"},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([80029])) that is different to the input size (torch.Size([80029, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n  return F.mse_loss(input, target, reduction=self.reduction)\n"]},{"output_type":"stream","name":"stdout","text":["[[152.47261  42.     ]\n [152.47261  76.     ]\n [152.47261  55.     ]\n [152.47261  28.     ]\n [152.47261  30.     ]\n [152.47261  35.     ]\n [152.47261  76.     ]\n [152.47261  50.     ]\n [152.47261  40.     ]\n [152.47261  95.     ]\n [152.47261  44.     ]\n [152.47261  60.     ]\n [152.47261  30.     ]\n [152.47261  99.     ]\n [152.47261 149.     ]\n [152.47261  60.     ]\n [152.47261  55.     ]\n [152.47261  30.     ]\n [152.47261  45.     ]\n [152.47261  48.     ]\n [152.47261  60.     ]\n [152.47261  37.     ]\n [152.47261  75.     ]\n [152.47261  55.     ]\n [152.47261  45.     ]\n [152.47261  66.     ]\n [152.47261  32.     ]\n [152.47261  32.     ]\n [152.47261  18.     ]\n [152.47261  59.     ]\n [152.47261  39.     ]\n [152.47261  69.     ]\n [152.47261  69.     ]\n [152.47261  69.     ]\n [152.47261  56.     ]\n [152.47261  50.     ]\n [152.47261  80.     ]\n [152.47261  80.     ]\n [152.47261  35.     ]\n [152.47261  50.     ]\n [152.47261  60.     ]\n [152.47261  60.     ]\n [152.47261  39.     ]\n [152.47261  41.     ]\n [152.47261  45.     ]\n [152.47261  50.     ]\n [152.47261  91.     ]\n [152.47261  35.     ]\n [152.47261  30.     ]\n [152.47261  16.     ]\n [152.47261  22.     ]\n [152.47261  92.     ]\n [152.47261  95.     ]\n [152.47261  26.     ]\n [152.47261  25.     ]\n [152.47261  25.     ]\n [152.47261  55.     ]\n [152.47261  35.     ]\n [152.47261  35.     ]\n [152.47261  41.     ]\n [152.47261 298.     ]\n [152.47261  40.     ]\n [152.47261 371.     ]\n [152.47261  17.     ]\n [152.47261 100.     ]\n [152.47261 192.     ]\n [152.47261  25.     ]\n [152.47261  45.     ]\n [152.47261  50.     ]\n [152.47261  22.     ]\n [152.47261  25.     ]\n [152.47261  23.     ]\n [152.47261 351.     ]\n [152.47261  18.     ]\n [152.47261  43.     ]\n [152.47261  30.     ]\n [152.47261  35.     ]\n [152.47261  45.     ]\n [152.47261 245.     ]\n [152.47261  69.     ]\n [152.47261  39.     ]\n [152.47261  80.     ]\n [152.47261  65.     ]\n [152.47261  40.     ]\n [152.47261  30.     ]\n [152.47261  50.     ]\n [152.47261  50.     ]\n [152.47261  42.     ]\n [152.47261  64.     ]\n [152.47261  28.     ]\n [152.47261  19.     ]\n [152.47261  74.     ]\n [152.47261  74.     ]\n [152.47261 149.     ]\n [152.47261 100.     ]\n [152.47261  43.     ]\n [152.47261  43.     ]\n [152.47261  55.     ]\n [152.47261  97.     ]\n [152.47261  50.     ]]\nModel saved in run_id=f35d03af-4f9b-4b6e-a931-bec842452fc3\nsds://lake.trident.com/2d2772c8-0868-471e-a900-374b70d8e1ce/b5dc4923-fd26-4a73-a136-d91324182e4c/f35d03af-4f9b-4b6e-a931-bec842452fc3/artifacts/model\nNeural Net parameters:\n                  batchsize: 32 \n\n                  learning_rate: 0.1 \n\n                  num_epochs: 100 \n\n                  Neurons: 32 l2_neurons \n\n                  MSE: 26028.58203125\n[[152.00314  42.     ]\n [152.00314  76.     ]\n [152.00314  55.     ]\n [152.00314  28.     ]\n [152.00314  30.     ]\n [152.00314  35.     ]\n [152.00314  76.     ]\n [152.00314  50.     ]\n [152.00314  40.     ]\n [152.00314  95.     ]\n [152.00314  44.     ]\n [152.00314  60.     ]\n [152.00314  30.     ]\n [152.00314  99.     ]\n [152.00314 149.     ]\n [152.00314  60.     ]\n [152.00314  55.     ]\n [152.00314  30.     ]\n [152.00314  45.     ]\n [152.00314  48.     ]\n [152.00314  60.     ]\n [152.00314  37.     ]\n [152.00314  75.     ]\n [152.00314  55.     ]\n [152.00314  45.     ]\n [152.00314  66.     ]\n [152.00314  32.     ]\n [152.00314  32.     ]\n [152.00314  18.     ]\n [152.00314  59.     ]\n [152.00314  39.     ]\n [152.00314  69.     ]\n [152.00314  69.     ]\n [152.00314  69.     ]\n [152.00314  56.     ]\n [152.00314  50.     ]\n [152.00314  80.     ]\n [152.00314  80.     ]\n [152.00314  35.     ]\n [152.00314  50.     ]\n [152.00314  60.     ]\n [152.00314  60.     ]\n [152.00314  39.     ]\n [152.00314  41.     ]\n [152.00314  45.     ]\n [152.00314  50.     ]\n [152.00314  91.     ]\n [152.00314  35.     ]\n [152.00314  30.     ]\n [152.00314  16.     ]\n [152.00314  22.     ]\n [152.00314  92.     ]\n [152.00314  95.     ]\n [152.00314  26.     ]\n [152.00314  25.     ]\n [152.00314  25.     ]\n [152.00314  55.     ]\n [152.00314  35.     ]\n [152.00314  35.     ]\n [152.00314  41.     ]\n [152.00314 298.     ]\n [152.00314  40.     ]\n [152.00314 371.     ]\n [152.00314  17.     ]\n [152.00314 100.     ]\n [152.00314 192.     ]\n [152.00314  25.     ]\n [152.00314  45.     ]\n [152.00314  50.     ]\n [152.00314  22.     ]\n [152.00314  25.     ]\n [152.00314  23.     ]\n [152.00314 351.     ]\n [152.00314  18.     ]\n [152.00314  43.     ]\n [152.00314  30.     ]\n [152.00314  35.     ]\n [152.00314  45.     ]\n [152.00314 245.     ]\n [152.00314  69.     ]\n [152.00314  39.     ]\n [152.00314  80.     ]\n [152.00314  65.     ]\n [152.00314  40.     ]\n [152.00314  30.     ]\n [152.00314  50.     ]\n [152.00314  50.     ]\n [152.00314  42.     ]\n [152.00314  64.     ]\n [152.00314  28.     ]\n [152.00314  19.     ]\n [152.00314  74.     ]\n [152.00314  74.     ]\n [152.00314 149.     ]\n [152.00314 100.     ]\n [152.00314  43.     ]\n [152.00314  43.     ]\n [152.00314  55.     ]\n [152.00314  97.     ]\n [152.00314  50.     ]]\nModel saved in run_id=9fc5ea6a-ba76-44f7-bad6-d78ab24a60ab\nsds://lake.trident.com/2d2772c8-0868-471e-a900-374b70d8e1ce/b5dc4923-fd26-4a73-a136-d91324182e4c/9fc5ea6a-ba76-44f7-bad6-d78ab24a60ab/artifacts/model\nNeural Net parameters:\n                  batchsize: 32 \n\n                  learning_rate: 0.1 \n\n                  num_epochs: 100 \n\n                  Neurons: 64 l2_neurons \n\n                  MSE: 26028.283203125\n[[155.3908  42.    ]\n [155.3908  76.    ]\n [155.3908  55.    ]\n [155.3908  28.    ]\n [155.3908  30.    ]\n [155.3908  35.    ]\n [155.3908  76.    ]\n [155.3908  50.    ]\n [155.3908  40.    ]\n [155.3908  95.    ]\n [155.3908  44.    ]\n [155.3908  60.    ]\n [155.3908  30.    ]\n [155.3908  99.    ]\n [155.3908 149.    ]\n [155.3908  60.    ]\n [155.3908  55.    ]\n [155.3908  30.    ]\n [155.3908  45.    ]\n [155.3908  48.    ]\n [155.3908  60.    ]\n [155.3908  37.    ]\n [155.3908  75.    ]\n [155.3908  55.    ]\n [155.3908  45.    ]\n [155.3908  66.    ]\n [155.3908  32.    ]\n [155.3908  32.    ]\n [155.3908  18.    ]\n [155.3908  59.    ]\n [155.3908  39.    ]\n [155.3908  69.    ]\n [155.3908  69.    ]\n [155.3908  69.    ]\n [155.3908  56.    ]\n [155.3908  50.    ]\n [155.3908  80.    ]\n [155.3908  80.    ]\n [155.3908  35.    ]\n [155.3908  50.    ]\n [155.3908  60.    ]\n [155.3908  60.    ]\n [155.3908  39.    ]\n [155.3908  41.    ]\n [155.3908  45.    ]\n [155.3908  50.    ]\n [155.3908  91.    ]\n [155.3908  35.    ]\n [155.3908  30.    ]\n [155.3908  16.    ]\n [155.3908  22.    ]\n [155.3908  92.    ]\n [155.3908  95.    ]\n [155.3908  26.    ]\n [155.3908  25.    ]\n [155.3908  25.    ]\n [155.3908  55.    ]\n [155.3908  35.    ]\n [155.3908  35.    ]\n [155.3908  41.    ]\n [155.3908 298.    ]\n [155.3908  40.    ]\n [155.3908 371.    ]\n [155.3908  17.    ]\n [155.3908 100.    ]\n [155.3908 192.    ]\n [155.3908  25.    ]\n [155.3908  45.    ]\n [155.3908  50.    ]\n [155.3908  22.    ]\n [155.3908  25.    ]\n [155.3908  23.    ]\n [155.3908 351.    ]\n [155.3908  18.    ]\n [155.3908  43.    ]\n [155.3908  30.    ]\n [155.3908  35.    ]\n [155.3908  45.    ]\n [155.3908 245.    ]\n [155.3908  69.    ]\n [155.3908  39.    ]\n [155.3908  80.    ]\n [155.3908  65.    ]\n [155.3908  40.    ]\n [155.3908  30.    ]\n [155.3908  50.    ]\n [155.3908  50.    ]\n [155.3908  42.    ]\n [155.3908  64.    ]\n [155.3908  28.    ]\n [155.3908  19.    ]\n [155.3908  74.    ]\n [155.3908  74.    ]\n [155.3908 149.    ]\n [155.3908 100.    ]\n [155.3908  43.    ]\n [155.3908  43.    ]\n [155.3908  55.    ]\n [155.3908  97.    ]\n [155.3908  50.    ]]\nModel saved in run_id=d7e45cc1-0c3f-4005-9897-3c94b678920b\nsds://lake.trident.com/2d2772c8-0868-471e-a900-374b70d8e1ce/b5dc4923-fd26-4a73-a136-d91324182e4c/d7e45cc1-0c3f-4005-9897-3c94b678920b/artifacts/model\nNeural Net parameters:\n                  batchsize: 64 \n\n                  learning_rate: 0.1 \n\n                  num_epochs: 100 \n\n                  Neurons: 32 l2_neurons \n\n                  MSE: 26040.3203125\n[[152.5777  42.    ]\n [152.5777  76.    ]\n [152.5777  55.    ]\n [152.5777  28.    ]\n [152.5777  30.    ]\n [152.5777  35.    ]\n [152.5777  76.    ]\n [152.5777  50.    ]\n [152.5777  40.    ]\n [152.5777  95.    ]\n [152.5777  44.    ]\n [152.5777  60.    ]\n [152.5777  30.    ]\n [152.5777  99.    ]\n [152.5777 149.    ]\n [152.5777  60.    ]\n [152.5777  55.    ]\n [152.5777  30.    ]\n [152.5777  45.    ]\n [152.5777  48.    ]\n [152.5777  60.    ]\n [152.5777  37.    ]\n [152.5777  75.    ]\n [152.5777  55.    ]\n [152.5777  45.    ]\n [152.5777  66.    ]\n [152.5777  32.    ]\n [152.5777  32.    ]\n [152.5777  18.    ]\n [152.5777  59.    ]\n [152.5777  39.    ]\n [152.5777  69.    ]\n [152.5777  69.    ]\n [152.5777  69.    ]\n [152.5777  56.    ]\n [152.5777  50.    ]\n [152.5777  80.    ]\n [152.5777  80.    ]\n [152.5777  35.    ]\n [152.5777  50.    ]\n [152.5777  60.    ]\n [152.5777  60.    ]\n [152.5777  39.    ]\n [152.5777  41.    ]\n [152.5777  45.    ]\n [152.5777  50.    ]\n [152.5777  91.    ]\n [152.5777  35.    ]\n [152.5777  30.    ]\n [152.5777  16.    ]\n [152.5777  22.    ]\n [152.5777  92.    ]\n [152.5777  95.    ]\n [152.5777  26.    ]\n [152.5777  25.    ]\n [152.5777  25.    ]\n [152.5777  55.    ]\n [152.5777  35.    ]\n [152.5777  35.    ]\n [152.5777  41.    ]\n [152.5777 298.    ]\n [152.5777  40.    ]\n [152.5777 371.    ]\n [152.5777  17.    ]\n [152.5777 100.    ]\n [152.5777 192.    ]\n [152.5777  25.    ]\n [152.5777  45.    ]\n [152.5777  50.    ]\n [152.5777  22.    ]\n [152.5777  25.    ]\n [152.5777  23.    ]\n [152.5777 351.    ]\n [152.5777  18.    ]\n [152.5777  43.    ]\n [152.5777  30.    ]\n [152.5777  35.    ]\n [152.5777  45.    ]\n [152.5777 245.    ]\n [152.5777  69.    ]\n [152.5777  39.    ]\n [152.5777  80.    ]\n [152.5777  65.    ]\n [152.5777  40.    ]\n [152.5777  30.    ]\n [152.5777  50.    ]\n [152.5777  50.    ]\n [152.5777  42.    ]\n [152.5777  64.    ]\n [152.5777  28.    ]\n [152.5777  19.    ]\n [152.5777  74.    ]\n [152.5777  74.    ]\n [152.5777 149.    ]\n [152.5777 100.    ]\n [152.5777  43.    ]\n [152.5777  43.    ]\n [152.5777  55.    ]\n [152.5777  97.    ]\n [152.5777  50.    ]]\nModel saved in run_id=bf7a9843-d4e7-43e3-8112-aed03f3b7ca7\nsds://lake.trident.com/2d2772c8-0868-471e-a900-374b70d8e1ce/b5dc4923-fd26-4a73-a136-d91324182e4c/bf7a9843-d4e7-43e3-8112-aed03f3b7ca7/artifacts/model\nNeural Net parameters:\n                  batchsize: 64 \n\n                  learning_rate: 0.1 \n\n                  num_epochs: 100 \n\n                  Neurons: 64 l2_neurons \n\n                  MSE: 26028.708984375\n[[ 76.82075   42.      ]\n [125.21117   76.      ]\n [ 76.82075   55.      ]\n [ 76.82075   28.      ]\n [111.95582   30.      ]\n [ 76.82075   35.      ]\n [ 76.82075   76.      ]\n [ 76.82075   50.      ]\n [ 76.82075   40.      ]\n [124.8261    95.      ]\n [ 76.82075   44.      ]\n [ 76.82075   60.      ]\n [129.9991    30.      ]\n [ 76.82075   99.      ]\n [ 76.82075  149.      ]\n [ 76.82075   60.      ]\n [ 76.82075   55.      ]\n [ 76.82075   30.      ]\n [109.83189   45.      ]\n [ 76.82075   48.      ]\n [ 76.82075   60.      ]\n [ 76.82075   37.      ]\n [ 76.82075   75.      ]\n [ 76.82075   55.      ]\n [ 76.82075   45.      ]\n [ 76.82075   66.      ]\n [ 76.82075   32.      ]\n [ 76.82075   32.      ]\n [ 76.82075   18.      ]\n [111.56918   59.      ]\n [ 76.82075   39.      ]\n [ 76.82075   69.      ]\n [ 76.82075   69.      ]\n [ 76.82075   69.      ]\n [115.201     56.      ]\n [ 76.82075   50.      ]\n [163.78185   80.      ]\n [163.78185   80.      ]\n [ 76.82075   35.      ]\n [ 76.82075   50.      ]\n [155.62021   60.      ]\n [155.62021   60.      ]\n [ 76.82075   39.      ]\n [ 76.82075   41.      ]\n [ 76.82075   45.      ]\n [ 76.82075   50.      ]\n [ 76.82075   91.      ]\n [ 76.82075   35.      ]\n [ 76.82075   30.      ]\n [ 76.82075   16.      ]\n [ 76.82075   22.      ]\n [ 76.82075   92.      ]\n [170.79533   95.      ]\n [ 76.82075   26.      ]\n [ 76.82075   25.      ]\n [ 76.82075   25.      ]\n [ 76.82075   55.      ]\n [ 76.82075   35.      ]\n [ 76.82075   35.      ]\n [116.34583   41.      ]\n [ 76.82075  298.      ]\n [ 76.82075   40.      ]\n [ 76.82075  371.      ]\n [ 76.82075   17.      ]\n [ 76.82075  100.      ]\n [ 76.82075  192.      ]\n [ 76.82075   25.      ]\n [ 76.82075   45.      ]\n [ 76.82075   50.      ]\n [ 76.82075   22.      ]\n [ 76.82075   25.      ]\n [ 76.82075   23.      ]\n [ 76.82075  351.      ]\n [ 76.82075   18.      ]\n [117.652626  43.      ]\n [ 76.82075   30.      ]\n [ 76.82075   35.      ]\n [ 76.82075   45.      ]\n [ 76.82075  245.      ]\n [ 76.82075   69.      ]\n [113.99955   39.      ]\n [ 76.82075   80.      ]\n [ 76.82075   65.      ]\n [ 76.82075   40.      ]\n [ 76.82075   30.      ]\n [ 76.82075   50.      ]\n [ 76.82075   50.      ]\n [ 76.82075   42.      ]\n [ 76.82075   64.      ]\n [169.6889    28.      ]\n [ 76.82075   19.      ]\n [112.56744   74.      ]\n [112.56744   74.      ]\n [ 76.82075  149.      ]\n [ 76.82075  100.      ]\n [ 76.82075   43.      ]\n [ 76.82075   43.      ]\n [ 76.82075   55.      ]\n [115.65124   97.      ]\n [118.122604  50.      ]]\nModel saved in run_id=7fd44279-4cbe-43e6-81ea-06acc24843ab\nsds://lake.trident.com/2d2772c8-0868-471e-a900-374b70d8e1ce/b5dc4923-fd26-4a73-a136-d91324182e4c/7fd44279-4cbe-43e6-81ea-06acc24843ab/artifacts/model\nNeural Net parameters:\n                  batchsize: 32 \n\n                  learning_rate: 0.01 \n\n                  num_epochs: 100 \n\n                  Neurons: 32 l2_neurons \n\n                  MSE: 36977.53515625\n"]}],"execution_count":17,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"87575e9a-a6a0-4914-8590-cee379bb5266"},{"cell_type":"code","source":["# Load in Pytorch models\n","\n","loaded_model = mlflow.pytorch.load_model('sds://lake.trident.com/2d2772c8-0868-471e-a900-374b70d8e1ce/f2f0946d-3623-46d6-a0ab-a7c5853ccb4a/ccfff665-0473-443a-833f-c4cf3b7bbb7c/artifact/model')\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"0bffae6c-d183-4707-9c3b-5028e5efadfb","statement_id":13,"state":"finished","livy_statement_state":"available","queued_time":"2023-09-08T12:51:43.1552989Z","session_start_time":null,"execution_start_time":"2023-09-08T12:51:43.5465796Z","execution_finish_time":"2023-09-08T12:51:43.8442216Z","spark_jobs":{"numbers":{"SUCCEEDED":0,"FAILED":0,"RUNNING":0,"UNKNOWN":0},"jobs":[],"limit":20,"rule":"ALL_DESC"},"parent_msg_id":"20e68360-3a07-45b0-82bc-08e73b0f9253"},"text/plain":"StatementMeta(, 0bffae6c-d183-4707-9c3b-5028e5efadfb, 13, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stderr","text":["2023-09-08:12:51:43,544 ERROR    [synapse_mlflow_utils.py:398] [fabric mlflow plugin]: <class 'synapse.ml.mlflow.artifact_repo.TridentMLflowArtifactRepository'>.list_artifacts exception\n2023-09-08:12:51:43,546 ERROR    [synapse_mlflow_utils.py:398] [fabric mlflow plugin]: <class 'mlflow.store.artifact.artifact_repo.ArtifactRepository'>._is_directory exception\n2023-09-08:12:51:43,548 ERROR    [synapse_mlflow_utils.py:398] [fabric mlflow plugin]: <class 'mlflow.store.artifact.artifact_repo.ArtifactRepository'>.download_artifacts exception\n"]},{"output_type":"error","ename":"ResourceNotFoundError","evalue":"The specified path does not exist.\nRequestId:550928b8-201f-002b-5753-e2022e000000\nTime:2023-09-08T12:51:43.5413722Z\nErrorCode:PathNotFound","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mResourceNotFoundError\u001b[0m                     Traceback (most recent call last)","Cell \u001b[0;32mIn[38], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load in Pytorch models\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m loaded_model \u001b[38;5;241m=\u001b[39m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpytorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msds://lake.trident.com/2d2772c8-0868-471e-a900-374b70d8e1ce/f2f0946d-3623-46d6-a0ab-a7c5853ccb4a/ccfff665-0473-443a-833f-c4cf3b7bbb7c/artifact/model\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/cluster-env/trident_env/lib/python3.10/site-packages/mlflow/pytorch/__init__.py:726\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(model_uri, dst_path, **kwargs)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    668\u001b[0m \u001b[38;5;124;03mLoad a PyTorch model from a local file or a run.\u001b[39;00m\n\u001b[1;32m    669\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    722\u001b[0m \u001b[38;5;124;03m    predict X: 30.0, y_pred: 60.48\u001b[39;00m\n\u001b[1;32m    723\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m--> 726\u001b[0m local_model_path \u001b[38;5;241m=\u001b[39m \u001b[43m_download_artifact_from_uri\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifact_uri\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdst_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    727\u001b[0m pytorch_conf \u001b[38;5;241m=\u001b[39m _get_flavor_configuration(model_path\u001b[38;5;241m=\u001b[39mlocal_model_path, flavor_name\u001b[38;5;241m=\u001b[39mFLAVOR_NAME)\n\u001b[1;32m    728\u001b[0m _add_code_from_conf_to_system_path(local_model_path, pytorch_conf)\n","File \u001b[0;32m~/cluster-env/trident_env/lib/python3.10/site-packages/mlflow/tracking/artifact_utils.py:100\u001b[0m, in \u001b[0;36m_download_artifact_from_uri\u001b[0;34m(artifact_uri, output_path)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03m:param artifact_uri: The *absolute* URI of the artifact to download.\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m:param output_path: The local filesystem path to which to download the artifact. If unspecified,\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;124;03m                    a local output path will be created.\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     99\u001b[0m root_uri, artifact_path \u001b[38;5;241m=\u001b[39m _get_root_uri_and_artifact_path(artifact_uri)\n\u001b[0;32m--> 100\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_artifact_repository\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifact_uri\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mroot_uri\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_artifacts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43martifact_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_path\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/cluster-env/trident_env/lib/python3.10/site-packages/synapse/ml/mlflow/synapse_mlflow_utils.py:384\u001b[0m, in \u001b[0;36mprotect_module.<locals>.catch_and_log_exception.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 384\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m RestException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39merror_code \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRESOURCE_DOES_NOT_EXIST\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n","File \u001b[0;32m~/cluster-env/trident_env/lib/python3.10/site-packages/mlflow/store/artifact/artifact_repo.py:241\u001b[0m, in \u001b[0;36mArtifactRepository.download_artifacts\u001b[0;34m(self, artifact_path, dst_path)\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[1;32m    233\u001b[0m         message\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    234\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe destination path for downloaded artifacts must be a directory!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    237\u001b[0m         error_code\u001b[38;5;241m=\u001b[39mINVALID_PARAMETER_VALUE,\n\u001b[1;32m    238\u001b[0m     )\n\u001b[1;32m    240\u001b[0m \u001b[38;5;66;03m# Check if the artifacts points to a directory\u001b[39;00m\n\u001b[0;32m--> 241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_is_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    242\u001b[0m     dst_local_path, inflight_downloads \u001b[38;5;241m=\u001b[39m async_download_artifact_dir(\n\u001b[1;32m    243\u001b[0m         src_artifact_dir_path\u001b[38;5;241m=\u001b[39martifact_path, dst_local_dir_path\u001b[38;5;241m=\u001b[39mdst_path\n\u001b[1;32m    244\u001b[0m     )\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n","File \u001b[0;32m~/cluster-env/trident_env/lib/python3.10/site-packages/synapse/ml/mlflow/synapse_mlflow_utils.py:384\u001b[0m, in \u001b[0;36mprotect_module.<locals>.catch_and_log_exception.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 384\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m RestException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39merror_code \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRESOURCE_DOES_NOT_EXIST\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n","File \u001b[0;32m~/cluster-env/trident_env/lib/python3.10/site-packages/mlflow/store/artifact/artifact_repo.py:79\u001b[0m, in \u001b[0;36mArtifactRepository._is_directory\u001b[0;34m(self, artifact_path)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_is_directory\u001b[39m(\u001b[38;5;28mself\u001b[39m, artifact_path):\n\u001b[0;32m---> 79\u001b[0m     listing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_artifacts\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(listing) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n","File \u001b[0;32m~/cluster-env/trident_env/lib/python3.10/site-packages/synapse/ml/mlflow/synapse_mlflow_utils.py:384\u001b[0m, in \u001b[0;36mprotect_module.<locals>.catch_and_log_exception.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 384\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m RestException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39merror_code \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRESOURCE_DOES_NOT_EXIST\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n","File \u001b[0;32m~/cluster-env/trident_env/lib/python3.10/site-packages/synapse/ml/mlflow/artifact_repo.py:111\u001b[0m, in \u001b[0;36mTridentMLflowArtifactRepository.list_artifacts\u001b[0;34m(self, path, recursive)\u001b[0m\n\u001b[1;32m    107\u001b[0m files: ItemPaged[PathProperties] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_paths(\n\u001b[1;32m    108\u001b[0m     path\u001b[38;5;241m=\u001b[39mfile_path, recursive\u001b[38;5;241m=\u001b[39mrecursive\n\u001b[1;32m    109\u001b[0m )\n\u001b[1;32m    110\u001b[0m res: List[FileInfo] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 111\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m files:\n\u001b[1;32m    112\u001b[0m     file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mrelpath(f\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39monelake_base_path)\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m file_path \u001b[38;5;241m==\u001b[39m path:  \u001b[38;5;66;03m# needs to exclude itself(this is not a prefix match)\u001b[39;00m\n","File \u001b[0;32m~/cluster-env/trident_env/lib/python3.10/site-packages/azure/core/paging.py:124\u001b[0m, in \u001b[0;36mItemPaged.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_page_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_page_iterator \u001b[38;5;241m=\u001b[39m itertools\u001b[38;5;241m.\u001b[39mchain\u001b[38;5;241m.\u001b[39mfrom_iterable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mby_page())\n\u001b[0;32m--> 124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_page_iterator\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/cluster-env/trident_env/lib/python3.10/site-packages/azure/core/paging.py:76\u001b[0m, in \u001b[0;36mPageIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnd of paging\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_next\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontinuation_token\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m AzureError \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m error\u001b[38;5;241m.\u001b[39mcontinuation_token:\n","File \u001b[0;32m~/cluster-env/trident_env/lib/python3.10/site-packages/azure/storage/filedatalake/_list_paths_helper.py:158\u001b[0m, in \u001b[0;36mPathPropertiesPaged._get_next_cb\u001b[0;34m(self, continuation_token)\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_command(\n\u001b[1;32m    151\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecursive,\n\u001b[1;32m    152\u001b[0m         continuation\u001b[38;5;241m=\u001b[39mcontinuation_token \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    155\u001b[0m         upn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupn,\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39mreturn_headers_and_deserialized_path_list)\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HttpResponseError \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[0;32m--> 158\u001b[0m     \u001b[43mprocess_storage_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/cluster-env/trident_env/lib/python3.10/site-packages/azure/storage/filedatalake/_deserialize.py:215\u001b[0m, in \u001b[0;36mprocess_storage_error\u001b[0;34m(storage_error)\u001b[0m\n\u001b[1;32m    211\u001b[0m error\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m (error\u001b[38;5;241m.\u001b[39mmessage,)\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;66;03m# `from None` prevents us from double printing the exception (suppresses generated layer error context)\u001b[39;00m\n\u001b[0;32m--> 215\u001b[0m     \u001b[43mexec\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mraise error from None\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m   \u001b[38;5;66;03m# pylint: disable=exec-used # nosec\u001b[39;00m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mSyntaxError\u001b[39;00m:\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\n","File \u001b[0;32m<string>:1\u001b[0m\n","File \u001b[0;32m~/cluster-env/trident_env/lib/python3.10/site-packages/azure/storage/filedatalake/_list_paths_helper.py:150\u001b[0m, in \u001b[0;36mPathPropertiesPaged._get_next_cb\u001b[0;34m(self, continuation_token)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_next_cb\u001b[39m(\u001b[38;5;28mself\u001b[39m, continuation_token):\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_command\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecursive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcontinuation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontinuation_token\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresults_per_page\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m            \u001b[49m\u001b[43mupn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_headers_and_deserialized_path_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m HttpResponseError \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[1;32m    158\u001b[0m         process_storage_error(error)\n","File \u001b[0;32m~/cluster-env/trident_env/lib/python3.10/site-packages/azure/core/tracing/decorator.py:76\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m span_impl_type \u001b[38;5;241m=\u001b[39m settings\u001b[38;5;241m.\u001b[39mtracing_implementation()\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m span_impl_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n","File \u001b[0;32m~/cluster-env/trident_env/lib/python3.10/site-packages/azure/storage/filedatalake/_generated/operations/_file_system_operations.py:737\u001b[0m, in \u001b[0;36mFileSystemOperations.list_paths\u001b[0;34m(self, recursive, request_id_parameter, timeout, continuation, path, max_results, upn, **kwargs)\u001b[0m\n\u001b[1;32m    734\u001b[0m response \u001b[38;5;241m=\u001b[39m pipeline_response\u001b[38;5;241m.\u001b[39mhttp_response\n\u001b[1;32m    736\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m200\u001b[39m]:\n\u001b[0;32m--> 737\u001b[0m     \u001b[43mmap_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatus_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    738\u001b[0m     error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deserialize\u001b[38;5;241m.\u001b[39mfailsafe_deserialize(_models\u001b[38;5;241m.\u001b[39mStorageError, pipeline_response)\n\u001b[1;32m    739\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HttpResponseError(response\u001b[38;5;241m=\u001b[39mresponse, model\u001b[38;5;241m=\u001b[39merror)\n","File \u001b[0;32m~/cluster-env/trident_env/lib/python3.10/site-packages/azure/core/exceptions.py:109\u001b[0m, in \u001b[0;36mmap_error\u001b[0;34m(status_code, response, error_map)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    108\u001b[0m error \u001b[38;5;241m=\u001b[39m error_type(response\u001b[38;5;241m=\u001b[39mresponse)\n\u001b[0;32m--> 109\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m error\n","\u001b[0;31mResourceNotFoundError\u001b[0m: The specified path does not exist.\nRequestId:550928b8-201f-002b-5753-e2022e000000\nTime:2023-09-08T12:51:43.5413722Z\nErrorCode:PathNotFound"]}],"execution_count":11,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"64b8dc9f-c0ae-45f1-87c3-5e7e52f9189e"},{"cell_type":"code","source":[],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"dd44d32f-89df-4fe7-9616-0dc383fa5166"}]}